
\documentclass[twoside]{article} 
\usepackage{aistats2017}

% If your paper is accepted, change the options for the package
% aistats2017 as follows:
%
%\usepackage[accepted]{aistats2017}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the nd of
% the first column of the first page.e

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts,amsthm}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{MnSymbol}
\usepackage{color}
\usepackage{graphicx} % more modern
\usepackage{subfigure} 
\usepackage{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{lineno}
\usepackage{thmtools,thm-restate}
\usepackage{xr}

\externaldocument{aistats_marina}
\externaldocument{experiments_aistats}
%\linenumbers



\def\A{\mathcal{A}}
\def\ga{\gamma_\mathcal{A}}
\def\Co{C^{\circ}}
\def\Coa{C^{\circ}_{\!\!\mathcal{A}}}
\def\Ca{C_{\!\mathcal{A}}}
\def\go{\gamma^{\circ}}
\def\goa{\gamma^{\circ}_{\A}}
\newcommand{\dt}[2]{\langle#1,#2\rangle}
\def\Olgl{\Omega_{\rm LGL}} % latent group Lasso norm
\def\tr{\rm tr}
\newcommand\itgset[1]{[\!\![#1]\!\!]}
\def\RR{\mathbb{R}}
\newcommand{\tblue}[1]{\textcolor{blue}{#1}}
\newcommand{\tred}[1]{\textcolor{red}{#1}}
\newcommand\TODO[1]{\tblue{TODO: \texttt{#1}}}
\def\st{\text{s.t.}}

\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{fact}{Fact}
\newtheorem{lemm}{Lemma}
\newtheorem{coro}{Corollary}

\begin{document}

\appendix
\section{Proof of Proposition 1}
\begin{prop}
If $f$ is assumed lower bounded by $0$ and if $\rho>f(0)$, or more generally if the level sets of $x \mapsto f(x)+\gamma_{\A}(x)$ are bounded and $\rho$ is sufficiently large, then the sequence $(\bar{x}^t)_t$ produced by the FCFW algorithm applied to the truncated cone constrained problem~(\ref{eq:trunc_cone}) and initialized at $(\bar{x}^0;\tau^0)=(0;0)$ is the same as the sequence $(x^t)_t$ produced by Algorithm~\ref{alg:colgen} initialized with $x^0=0$, with equivalent sequences of subproblems, active sets and decomposition coefficients.
\end{prop}
\begin{proof}
 First note that, the set of extreme points of the truncated cone $\{(x,\tau) \mid \gamma_{\A}(x) \leq \tau \leq \rho\}$ is $$\bar{\A}=\{(0;0)\} \cup \big \{(\rho a; \rho) \mid a \in \A \big \}.$$ so that all its non zero extreme points are in bijection with those of $\A$.
Then, for a given point $x$, the Frank-Wolfe directions computed respectively by FCFW in problems (\ref{eq:const_pb}) (or Algorithm~\ref{alg:colgen}) and (\ref{eq:trunc_cone}) Algorithm~\ref{alg:colgen}  are
$$
\begin{cases}
\: a^* &:=\arg\max_{a \in \A} \: \dt{\nabla f(x)}{a}\\
\: \bar{a}^* &:=\arg\max_{(\rho a;\rho u) \in \bar{\A}}\: \dt{\nabla f(x)}{a}+u,
\end{cases}
$$

and we have
$$\bar{a}^*=
\begin{cases}
(0;0) & \text{if} \quad \gamma_{\A}^{\circ}(\nabla f(x)) \leq 1\\
(\rho a^*;\rho) & \text{otherwise},
\end{cases}
$$
which shows that unless the atom $(0;0)$ is selected in $\bar{\A}$, it is the image of the regular FW direction mapped via $a \mapsto (\rho a;\rho)$. 
Note also that the atom $(0;0)$ is special in $\bar{\A}$ in that it is the only one for which the second component is different than $\rho$.
We now prove, by induction on $t$, the following statement:\\ $\mathcal{P}^t\!:\:$ {\it Letting $(\bar{x}^t,\bar{A}^t,\bar{c}^t)$ denote the triple of values of $x$, the matrix of active atoms of $\bar{\A}$ and the vector of coefficients $\bar{c}$ of decomposition of $x$ on these atoms, all generated by the FCFW algorithm, then (a) the first column of $\bar{A}^t$ is a column of zeroes corresponding to the atom $(0;0)$, so that we can write 
$$\bar{A}^t=
\begin{pmatrix}0 & \rho A^t \\ 0 & \rho u^t
\end{pmatrix} \in \RR^{(d+1) \times (1+k_t)}\quad \text{and} \quad \bar{c}^t=
\begin{pmatrix} d_0^t\\ d^t \end{pmatrix} \in \RR^{1+k_t},$$ (b) setting $x^t:=\bar{x}^t$, and $c^t=\rho d^t$ we have that $(x^t,A^t,c^t)$ is the $t$-th corresponding triple produced by Algorithm~\ref{eq:trunc_cone} and (c) $\tau^t=\rho(1-d_0^t)<\rho$ so that the truncation constraint $\{\tau \leq \rho\}$ is inactive.}
 
To prove $\mathcal{P}^0$, note that if $(x^0;\tau^0)=(0;0)$, then we trivially have $\bar{A}^0=(0;0)$ and $\bar{\A}^0$ has the desired form, we have $\bar{x}^0=c^0_0 \cdot 0_{d}=x^0$ with $\bar{c}^0= d_0^0=1$ so that $\bar{c}^0$ satisfies the simplex constraints; finally $\tau^0<\rho$.

We now assume $\mathcal{P}^{t-1}$ is true and prove that so is $\mathcal{P}^{t}$. In the FCFW algorithm, the new direction chosen cannot be $(0;0)$ since $d_0^{t-1}>0$, which entails this atoms is already in the active set and because the algorithm is fully corrective (which prevents the forward direction to be an atom already in the active set), so that it must be of the form $(\rho a^t,\rho )$ which, given that by induction $\bar{x}^{t-1}=x^{t-1}$, entails that $a^t$ is indeed the same direction as the one chosen by Algorithm~\ref{alg:colgen}.

Letting $\bar{A}^t$ is the matrix whose columns are the atoms used in the expansion of $x^t$, 
then $\bar{x}^t=A^t c^t$ and letting $x^t=\bar{x}^t$, then the triple $({x}^t,{A}^t,{c}^t)$ is the one generated by Algorithm~\ref{alg:colgen}. This entails that 
$\bar{A}^t$ is indeed of the announced form and that the sub-matrix $A^t$ is indeed the one used by Algorithm~\ref{alg:colgen}.

Now the optimization problem solved in the corrective step of FCFW is thus
\begin{align*}
\min_{x,\tau,d} \quad &  f(x) +\tau \quad \text{s.t.} \\ 
 & x=\rho A^t d , \quad \tau=\rho u^t d , \quad \bar{c}=(c_0;d) \in \Delta^{k_t+1},
\end{align*}
with $u^t=1_{k_t}^\top$ and $k_t$ the number of currently active atoms.

Eliminating $x$ and $\tau$ we obtain
$$\min_{d \geq 0} f(\rho A^t d)+\rho \, 1_{k_t}^\top d \quad \st \quad 1_{k_t}^\top d \leq 1,$$
and with the change of variable $c=\rho d$, we get 
$$\min_{c \geq 0} f(A^t c)+ \,  \|c\|_1 \quad \st \quad \|c\|_1 \leq \rho$$
But, since $\gamma_{\A^t}(x)=\inf \big \{\|c\|_1 \mid c \in \RR^{k_t}_+, \: x=A^t c \big \}$,  we can rewrite the previous problem equivalently as
$$\min_{x } f(x)+ \,  \gamma_{\A^t}(x) \quad \st \quad \gamma_{\A^t}(x) \leq \rho.$$
We first conclude the argument assuming $f\geq 0$ and $\rho>f(0)$. In that case, we have  $$\gamma_{\A^t}(x^t) \leq  f(x^t)+ \,  \gamma_{\A^t}(x^t) \leq  f(0)+ \,  \gamma_{\A^t}(0)=f(0)<\rho,$$ so that the inequality constraint is inactive for all $t$ at the optimum in the two last problems above
and can be removed. We thus showed that the optimization problem of the corrective step of the FCFW algorithm on problem (\ref{eq:trunc_cone}) is equivalent to the problem solved at step 6 of Algorithm~\ref{alg:colgen}, and that $\|c^t\|_1< \rho$ which entails that $d_0^t=1-\|d^t\|_1=1-\frac{1}{\rho}\|c\|_1>0$ and so that the atom $(0;0)$ remains in $\bar{\A}^{t+1}$. The induction step is completed which thus proves the result.

Now, if we do not assume that $f$ is lower bounded, but we assume instead that the level sets of $f+\gamma_{\A}$ are bounded, then Algorithm~\ref{alg:colgen} generates a sequence $x^t$ which is bounded since the sequence $\big (f(x^t)+\gamma_{\A^t}(x^t) \big )_t$ is a monotonically decreasing sequence. But since for all $x$, $f(x)+\gamma_{\A^t}(x) \geq f(x)+\gamma_{\A}(x)$, the monotonicity also implies that the sequence $(x^t)_t$ remains in the bounded set $\{x \mid  f(x)+\gamma_{\A}(x) \leq f(0)\}$. Since $f$ is assumed continuous this entails that $\big (f(x^t)\big )_t$ is bounded which entails that so is $\big (\gamma_{\A^t}(x^t) \big )_t$ so if $\rho$ is chosen such that $\rho> \sup_t \gamma_{\A^t}(x^t)$ then the FCFW algorithm applied on problem~(\ref{eq:trunc_cone}) will generate the same sequence as Algorithm~\ref{alg:colgen}. This value of $\rho$ is not known a priori, but is required by neither algorithms.
\end{proof}

\section{Rank one updates of the Hessian and its inverse in active-set}
Let  $H^{t}$ be the Hessian of the quadratic problem in active-set algorithm and $B^{t}$ its inverse. Let $Q$ be the Hessian of the quadratic function $f$. We have $H^{t}=A^{t\top}QA^{t}$. We use the Sherman–Morrison–Woodbury matrix inversion formula in the following equations.\\
\\
When we add an atom $a_{t+1}$, we have updates
$$
H^{t+1}=
\begin{bmatrix} 
H^{t} & v \\
v^{\top} & a_{t+1}^{\top}Qa_{t+1}
\end{bmatrix}
$$
and
$$
B^{t+1}=
\begin{bmatrix} 
B^{t}+\alpha B^{t}vv^{\top}B^{t} & -\alpha B^{t}v\\
-\alpha(B^{t}v)^{\top}& \alpha
\end{bmatrix}
$$
where $v=A^{t\top}Qa_{t+1}$ and $\alpha=(a_{t+1}^{\top}Qa_{t+1}-v^{\top}Bv)^{-1}$.\\
\\
When removing an atom, $H^{t+1}$ is obtained removing the corresponding column and row. For clarity, let us assume that we want to remove the last atom. We have
$$
H^{t}=
\begin{bmatrix} 
\tilde{H}^{t} & v \\
v^{\top} & \nu
\end{bmatrix}
$$
and
$$
B^{t+1}=
\begin{bmatrix} 
\tilde{B}^{t} & w\\
w^{\top}& \beta
\end{bmatrix}.
$$
Then,
\begin{align*}
&H^{t+1}=\tilde{H}^{t}, \\
\\
&B^{t+1} =\tilde{B}^{t} \\
		&+\frac{\beta \tilde{B}^{t}vv^{\top}\tilde{B}^{t}-(w^{\top}v-1)(wv^{\top}\tilde{B}^{t}+ \tilde{B}^{t}vw^{\top}) + v^{\top}\tilde{B}vww^{\top}}{(w^{\top}v-1)^2 - \beta v^{\top}\tilde{B}^{t}v}.\\
\end{align*}

%Let $s$ be the sparsity of the atoms, $k$ the number of atoms and $p$ the dimension. 
%\begin{table}[h]
%\caption{Computational cost for rank one updates of $H^{t}$ and $B^{t}$} 
%\label{tab:whs}
%\begin{center}
%\begin{tabular}{rrrrrr}
%           &{adding an atom}  & {removing an atom}\\
%\hline\\
%update of $H^{t}$   & $\mathcal{O}\big(\min(ks^2,ps+ks)\big)$ & -\\
%update of $B^{t}$   & $\mathcal{O}\big(k^2+\min(ks^2,ps+ks)\big)$ & $\mathcal{O}\big(k^2+\min(ks^2,ps+ks)\big)$\\
%\hline
%\end{tabular}
%\end{center}
%\end{table}


%\subsubsection*{References}
\bibliographystyle{apalike}
\bibliography{colgen}


\end{document}